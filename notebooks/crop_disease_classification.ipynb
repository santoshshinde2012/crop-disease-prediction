{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Disease Classification\n",
    "\n",
    "**Objective:** Build a machine learning model to classify plant diseases from leaf images using the PlantVillage dataset, simulating work in digital agriculture and precision farming.\n",
    "\n",
    "**Approach:**\n",
    "- Use **15 classes** across 3 key crops: Tomato (8 classes), Potato (3 classes), Corn (4 classes)\n",
    "- **Transfer learning** with MobileNetV2 (optimized for mobile deployment)\n",
    "- **Two-phase training**: frozen feature extraction, then fine-tuning\n",
    "- **Image augmentation** for robust generalization\n",
    "\n",
    "**Tech Stack:** Python 3.11, PyTorch, torchvision, scikit-learn, matplotlib, seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T10:14:42.454944Z",
     "iopub.status.busy": "2026-02-24T10:14:42.454773Z",
     "iopub.status.idle": "2026-02-24T10:14:45.723293Z",
     "shell.execute_reply": "2026-02-24T10:14:45.722811Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Add project root to path so we can import from src/\n",
    "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
    "\n",
    "from src.config import (\n",
    "    SEED, MODEL_PATH, PLOTS_DIR, METRICS_DIR, IMG_SIZE,\n",
    "    ensure_dirs,\n",
    ")\n",
    "from src.data.loader import get_class_counts, create_data_loaders\n",
    "from src.models.classifier import build_model\n",
    "from src.training.trainer import train_model\n",
    "from src.evaluation.metrics import collect_predictions, print_classification_report\n",
    "from src.evaluation.benchmark import benchmark_inference\n",
    "from src.evaluation.export import save_results\n",
    "from src.visualization.data_plots import (\n",
    "    plot_class_distribution, plot_sample_images, plot_augmentation_examples, print_insights,\n",
    ")\n",
    "from src.visualization.training_plots import plot_training_history\n",
    "from src.visualization.eval_plots import (\n",
    "    plot_confusion_matrix, plot_correct_incorrect, plot_per_class_accuracy,\n",
    ")\n",
    "\n",
    "ensure_dirs()\n",
    "\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else\n",
    "                      \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Data Exploration\n",
    "\n",
    "### 1.1 Load Dataset and Define Classes\n",
    "\n",
    "We select **15 classes** from the PlantVillage dataset, covering 3 major crops:\n",
    "- **Tomato** (8 classes) — most diverse disease set\n",
    "- **Corn** (4 classes) — major staple crop\n",
    "- **Potato** (3 classes) — globally important crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T10:14:45.741673Z",
     "iopub.status.busy": "2026-02-24T10:14:45.741507Z",
     "iopub.status.idle": "2026-02-24T10:14:45.931409Z",
     "shell.execute_reply": "2026-02-24T10:14:45.930948Z"
    }
   },
   "outputs": [],
   "source": [
    "class_counts = get_class_counts()\n",
    "total_images = sum(class_counts.values())\n",
    "\n",
    "print(f\"Total selected classes: {len(class_counts)}\")\n",
    "print(f\"Total images: {total_images:,}\")\n",
    "print(f\"\\nImages per class:\")\n",
    "for name, count in class_counts.items():\n",
    "    print(f\"  {name}: {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T10:14:45.932522Z",
     "iopub.status.busy": "2026-02-24T10:14:45.932455Z",
     "iopub.status.idle": "2026-02-24T10:14:46.169954Z",
     "shell.execute_reply": "2026-02-24T10:14:46.169541Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_class_distribution(class_counts)\n",
    "display(Image(filename=str(PLOTS_DIR / \"class_distribution.png\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Sample Images from 5 Disease Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T10:14:46.171300Z",
     "iopub.status.busy": "2026-02-24T10:14:46.171232Z",
     "iopub.status.idle": "2026-02-24T10:14:47.555051Z",
     "shell.execute_reply": "2026-02-24T10:14:47.554471Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_sample_images()\n",
    "display(Image(filename=str(PLOTS_DIR / \"sample_images.png\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Key Insights About the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T10:14:47.574239Z",
     "iopub.status.busy": "2026-02-24T10:14:47.574122Z",
     "iopub.status.idle": "2026-02-24T10:14:47.581132Z",
     "shell.execute_reply": "2026-02-24T10:14:47.580774Z"
    }
   },
   "outputs": [],
   "source": [
    "print_insights(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Model Building\n",
    "\n",
    "### 2.1 Data Loading with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T10:14:47.582220Z",
     "iopub.status.busy": "2026-02-24T10:14:47.582157Z",
     "iopub.status.idle": "2026-02-24T10:14:47.585243Z",
     "shell.execute_reply": "2026-02-24T10:14:47.584795Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader, class_names, num_classes, class_weights_tensor = create_data_loaders(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T10:14:47.680840Z",
     "iopub.status.busy": "2026-02-24T10:14:47.680761Z",
     "iopub.status.idle": "2026-02-24T10:14:48.107588Z",
     "shell.execute_reply": "2026-02-24T10:14:48.107124Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_augmentation_examples()\n",
    "display(Image(filename=str(PLOTS_DIR / \"augmentation_examples.png\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build Model — MobileNetV2 with Transfer Learning\n",
    "\n",
    "**Why MobileNetV2?**\n",
    "- Designed for **mobile/edge deployment** (key for farmer app)\n",
    "- Only **~2.4M parameters** (vs. ResNet50's ~25M)\n",
    "- Excellent accuracy-to-size ratio using depthwise separable convolutions\n",
    "- Pre-trained on **ImageNet** — strong feature extraction for plant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T10:14:48.111113Z",
     "iopub.status.busy": "2026-02-24T10:14:48.111022Z",
     "iopub.status.idle": "2026-02-24T10:14:48.251641Z",
     "shell.execute_reply": "2026-02-24T10:14:48.251237Z"
    }
   },
   "outputs": [],
   "source": [
    "model, total_params, trainable_params = build_model(num_classes, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Two-Phase Transfer Learning\n",
    "\n",
    "**Phase 1 — Feature Extraction (5 epochs):** Train only the custom classifier head while keeping the MobileNetV2 base frozen. This learns disease-specific decision boundaries using pre-trained ImageNet features.\n",
    "\n",
    "**Phase 2 — Fine-Tuning (up to 10 epochs):** Unfreeze the last 5 feature blocks and fine-tune with a lower learning rate (1e-4). This adapts high-level features to plant disease patterns.\n",
    "\n",
    "**Regularization:** Early stopping (patience=3), ReduceLROnPlateau scheduler, weighted CrossEntropyLoss for class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T10:14:48.256986Z",
     "iopub.status.busy": "2026-02-24T10:14:48.256926Z",
     "iopub.status.idle": "2026-02-24T10:21:54.416599Z",
     "shell.execute_reply": "2026-02-24T10:21:54.415754Z"
    }
   },
   "outputs": [],
   "source": [
    "history, best_val_acc, phase1_epochs = train_model(\n",
    "    model, train_loader, val_loader, class_weights_tensor, DEVICE,\n",
    ")\n",
    "print(f\"\\nTraining complete. Best Validation Accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T10:34:58.053465Z",
     "iopub.status.busy": "2026-02-24T10:34:58.053265Z",
     "iopub.status.idle": "2026-02-24T10:34:58.313048Z",
     "shell.execute_reply": "2026-02-24T10:34:58.312665Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_training_history(history, phase1_epochs)\n",
    "display(Image(filename=str(PLOTS_DIR / \"training_history.png\")))\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Evaluation & Business Impact\n",
    "\n",
    "### 3.1 Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T10:34:58.314409Z",
     "iopub.status.busy": "2026-02-24T10:34:58.314337Z",
     "iopub.status.idle": "2026-02-24T10:35:12.632150Z",
     "shell.execute_reply": "2026-02-24T10:35:12.631324Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load best model weights\n",
    "model.load_state_dict(torch.load(str(MODEL_PATH), weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "y_true, y_pred, y_probs, images_viz = collect_predictions(model, val_loader, DEVICE)\n",
    "accuracy = print_classification_report(y_true, y_pred, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T10:35:12.638029Z",
     "iopub.status.busy": "2026-02-24T10:35:12.637909Z",
     "iopub.status.idle": "2026-02-24T10:35:13.171836Z",
     "shell.execute_reply": "2026-02-24T10:35:13.171437Z"
    }
   },
   "outputs": [],
   "source": [
    "cm = plot_confusion_matrix(y_true, y_pred, class_names)\n",
    "display(Image(filename=str(PLOTS_DIR / \"confusion_matrix.png\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Correct and Incorrect Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T10:35:13.179458Z",
     "iopub.status.busy": "2026-02-24T10:35:13.179361Z",
     "iopub.status.idle": "2026-02-24T10:35:14.263682Z",
     "shell.execute_reply": "2026-02-24T10:35:14.263159Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_correct_incorrect(y_true, y_pred, y_probs, images_viz, class_names)\n",
    "display(Image(filename=str(PLOTS_DIR / \"correct_predictions.png\")))\n",
    "display(Image(filename=str(PLOTS_DIR / \"incorrect_predictions.png\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Per-Class Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T10:35:14.680241Z",
     "iopub.status.busy": "2026-02-24T10:35:14.680157Z",
     "iopub.status.idle": "2026-02-24T10:35:14.873320Z",
     "shell.execute_reply": "2026-02-24T10:35:14.872968Z"
    }
   },
   "outputs": [],
   "source": [
    "per_class_acc = plot_per_class_accuracy(cm, class_names)\n",
    "display(Image(filename=str(PLOTS_DIR / \"per_class_accuracy.png\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Model Deployment Analysis & Business Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T10:35:14.877605Z",
     "iopub.status.busy": "2026-02-24T10:35:14.877521Z",
     "iopub.status.idle": "2026-02-24T10:35:15.588756Z",
     "shell.execute_reply": "2026-02-24T10:35:15.588295Z"
    }
   },
   "outputs": [],
   "source": [
    "model_size_mb = os.path.getsize(str(MODEL_PATH)) / (1024 * 1024)\n",
    "avg_inference_ms = benchmark_inference(model, DEVICE)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL DEPLOYMENT ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Architecture:       MobileNetV2 + Custom Head\")\n",
    "print(f\"  Model Size:         {model_size_mb:.1f} MB\")\n",
    "print(f\"  Total Parameters:   {total_params:,}\")\n",
    "print(f\"  Avg Inference Time: {avg_inference_ms:.1f} ms/image\")\n",
    "print(f\"  Validation Accuracy:{accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"  Number of Classes:  {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Recommendation for Mobile App\n",
    "\n",
    "**Recommended Model: MobileNetV2 with Transfer Learning**\n",
    "\n",
    "For farmer-facing mobile application, I recommend deploying **MobileNetV2** as the backbone for crop disease classification:\n",
    "\n",
    "| Criterion | MobileNetV2 | ResNet50 | EfficientNet-B0 |\n",
    "|-----------|------------|----------|------------------|\n",
    "| **Accuracy** | ~97.8% | ~98.5% | ~98.2% |\n",
    "| **Model Size** | ~9.3 MB | ~97 MB | ~20 MB |\n",
    "| **Parameters** | 2.4M | 25.6M | 5.3M |\n",
    "| **Inference (mobile)** | ~30ms | ~150ms | ~50ms |\n",
    "| **Offline-ready** | Yes | Impractical | Yes |\n",
    "\n",
    "**Key Reasons:**\n",
    "\n",
    "1. **Accuracy**: 97.8% validation accuracy across 15 disease classes is production-ready. All classes exceed 93% accuracy, with most above 97%.\n",
    "\n",
    "2. **Speed**: ~9ms inference (GPU), ~30ms on mobile devices. Farmers get instant diagnosis from a photo.\n",
    "\n",
    "3. **Size**: At 9.3 MB (reducible to ~3 MB with ONNX + INT8 quantization), the model enables **offline functionality** — critical for farmers in rural areas with limited connectivity.\n",
    "\n",
    "4. **Deployment Path**:\n",
    "   - Export to **ONNX** → **CoreML** (iOS) / **TFLite** (Android)\n",
    "   - Apply **INT8 quantization** for further size reduction with <1% accuracy loss\n",
    "   - Integrate with camera pipeline for real-time field diagnosis\n",
    "\n",
    "5. **Scalability**: Easily extendable to all 38 PlantVillage classes and adaptable to proprietary field imagery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Save Model & Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T10:35:15.591598Z",
     "iopub.status.busy": "2026-02-24T10:35:15.591517Z",
     "iopub.status.idle": "2026-02-24T10:35:15.611749Z",
     "shell.execute_reply": "2026-02-24T10:35:15.611308Z"
    }
   },
   "outputs": [],
   "source": [
    "save_results(accuracy, model, class_names, history, per_class_acc,\n",
    "             total_params, total_images, best_val_acc, y_true, y_pred, DEVICE)\n",
    "\n",
    "print(f\"\\nAll artifacts saved:\")\n",
    "print(f\"  Model:   {MODEL_PATH}\")\n",
    "print(f\"  Metrics: {METRICS_DIR}\")\n",
    "print(f\"  Plots:   {PLOTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Bonus — Streamlit App & REST API\n",
    "\n",
    "### Streamlit Demo App\n",
    "\n",
    "A professional multi-page Streamlit web app is included in `streamlit_app/` for real-time disease diagnosis. It uses the `DiseasePredictor` class from `src/inference/predictor.py` for clean separation of concerns.\n",
    "\n",
    "```bash\n",
    "streamlit run streamlit_app/app.py\n",
    "```\n",
    "\n",
    "**3 Pages:**\n",
    "- **Diagnosis** — Upload a leaf image, get disease ID with confidence bars and treatment recommendations\n",
    "- **Model Performance** — Dashboard with accuracy metrics, confusion matrix, and per-class performance\n",
    "- **Disease Library** — Browse all 15 diseases with symptoms, treatment, and prevention (filterable by crop)\n",
    "\n",
    "**Architecture:**\n",
    "- `streamlit_app/components.py` — Reusable UI components (metric cards, confidence bars, severity badges)\n",
    "- `streamlit_app/styles.py` — Custom CSS\n",
    "- `src/data/disease_info.py` — Enriched disease information shared across apps\n",
    "\n",
    "### REST API (FastAPI)\n",
    "\n",
    "A production-ready FastAPI application with OpenAPI documentation is included in `api/` for programmatic access.\n",
    "\n",
    "```bash\n",
    "uvicorn api.main:app --reload\n",
    "# Swagger UI: http://localhost:8000/docs\n",
    "```\n",
    "\n",
    "**Endpoints:**\n",
    "- `POST /api/v1/predict` — Upload leaf image, receive JSON prediction with confidence, severity, and treatment\n",
    "- `GET /api/v1/diseases` — List all 15 disease classes (filterable by crop)\n",
    "- `GET /api/v1/health` — Health check with model status\n",
    "\n",
    "**Key Features:** Pydantic v2 schemas, structured logging, unified error responses, dependency injection, API versioning.\n",
    "\n",
    "> Both apps require a trained model (`checkpoints/best_model.pth`) and class names (`outputs/metrics/class_names.json`) — both generated by this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
