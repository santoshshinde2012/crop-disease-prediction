# Crop Disease Classifier — React Native Mobile App

Offline-first mobile app for crop disease classification. Runs a TFLite model entirely on-device — no internet required.

| Detail | Value |
|--------|-------|
| Model | MobileNetV2 (TFLite) |
| Accuracy | 97.8% |
| Classes | 15 (Corn, Potato, Tomato) |
| Inference | <100ms on-device |
| App size | ~9 MB model + ~16 KB data |

---

## Prerequisites

- **Node.js** 18+
- **React Native CLI** (not Expo)
- **Xcode 15+** (iOS) or **Android Studio** (Android)
- **CocoaPods** (iOS): `sudo gem install cocoapods`
- **Python 3.8+** (for model export only)

---

## Step 1: Export the TFLite Model

The app uses a `.tflite` model file for on-device inference via `react-native-fast-tflite`. Convert the trained PyTorch model:

```bash
# From the project root (crop-prediction/)
pip install torch torchvision onnx onnx-tf tensorflow

python scripts/export_model.py
```

This creates `mobile/assets/model/crop_disease_classifier.tflite` (~9 MB).

> **Note**: The app will not start without this file. You must run the export script first.

---

## Step 2: Install Dependencies

```bash
cd mobile
npm install
```

### iOS Only

```bash
cd ios
pod install
cd ..
```

---

## Step 3: Run the App

### iOS

**Option A — One command (opens Metro in a new Terminal window):**

```bash
npm run ios
```

**Option B — Two terminals (if Option A doesn't open the packager):**

1. Terminal 1: start the Metro bundler and leave it running:
   ```bash
   npm start
   ```
2. Terminal 2: build and run the app:
   ```bash
   npm run ios:no-packager
   ```

If you see **"No script URL provided. Make sure the packager is running"** in the simulator, Metro isn't running. Use Option B: run `npm start` in one terminal, then in the simulator press **⌘R** to reload, or run `npm run ios:no-packager` in a second terminal.

Or open `ios/CropDiseaseApp.xcworkspace` in Xcode and press Run (start Metro with `npm start` first).

### Android

```bash
npx react-native run-android
```

Make sure an Android emulator is running or a device is connected via USB.

---

## Step 4: Using the App

1. **Home** — Tap "Scan a Leaf" or navigate to the Scan tab
2. **Camera** — Point at a leaf, position it within the guide circle, tap the capture button
3. **Result** — View the diagnosis: disease name, confidence %, severity, treatment, and prevention tips
4. **History** — All past scans are saved locally for offline access
5. **Library** — Browse all 15 supported diseases with crop filter tabs

---

## Project Structure

```
mobile/
├── App.tsx                              # Entry: SafeAreaProvider → ModelProvider → Navigation
├── index.js                             # AppRegistry
├── package.json                         # Dependencies
├── tsconfig.json                        # TypeScript strict mode
├── babel.config.js                      # Reanimated plugin
├── metro.config.js                      # TFLite asset extension
│
├── assets/
│   ├── model/
│   │   └── crop_disease_classifier.tflite  # TFLite model (generated by export script)
│   ├── data/
│   │   ├── class_names.json                # 15 class names (from outputs/metrics/)
│   │   └── disease_info.json               # Disease details: symptoms, treatment, prevention
│   └── images/
│       └── demo_leaf.png                   # Bundled test image for simulator
│
├── src/
│   ├── types/index.ts                   # TypeScript interfaces (Disease, PredictionResult, etc.)
│   │
│   ├── theme/                           # Design system
│   │   ├── colors.ts                    #   Green palette (#2E7D32 primary)
│   │   ├── typography.ts                #   Font sizes and weights
│   │   ├── spacing.ts                   #   4px scale, border radii, shadows
│   │   └── index.ts                     #   Re-exports
│   │
│   ├── services/
│   │   ├── classifier.ts                # TFLite model load, ImageNet preprocessing, inference
│   │   ├── imageProcessor.ts            # Image resize (224x224) + RGBA pixel extraction
│   │   └── storage.ts                   # AsyncStorage CRUD for prediction history
│   │
│   ├── context/
│   │   └── ModelContext.tsx              # React context: loads model on mount, exposes predict()
│   │
│   ├── hooks/
│   │   └── usePrediction.ts             # Hook: imagePath → extract → predict → save to history
│   │
│   ├── navigation/
│   │   └── AppNavigator.tsx             # Bottom tabs (Home/Scan/History/Library) + Result stack
│   │
│   ├── components/
│   │   ├── ui/                          # Reusable primitives
│   │   │   ├── Card.tsx                 #   Elevated/outlined/filled card
│   │   │   ├── Button.tsx               #   Gradient primary, secondary, outline
│   │   │   ├── Badge.tsx                #   Severity badge (High/Moderate/Healthy)
│   │   │   ├── ConfidenceBar.tsx        #   Animated horizontal progress bar
│   │   │   └── LoadingOverlay.tsx       #   Full-screen spinner
│   │   ├── home/
│   │   │   ├── HeroSection.tsx          #   Green gradient hero with stats
│   │   │   └── FeatureCard.tsx          #   Icon + title + description
│   │   ├── result/
│   │   │   ├── DiagnosisCard.tsx        #   Disease name + confidence + image
│   │   │   ├── TreatmentCard.tsx        #   Treatment with urgency indicator
│   │   │   └── PreventionList.tsx       #   Checkmark list of prevention tips
│   │   └── library/
│   │       └── DiseaseListItem.tsx      #   Expandable disease card with animation
│   │
│   └── screens/
│       ├── HomeScreen.tsx               # Hero + feature cards + scan CTA
│       ├── CameraScreen.tsx             # Camera with leaf guide overlay
│       ├── ResultScreen.tsx             # Full diagnosis result
│       ├── HistoryScreen.tsx            # Past predictions list
│       └── DiseaseLibraryScreen.tsx     # Browsable disease catalog
```

> **Note**: The model export script lives at `scripts/export_model.py` in the project root (not inside `mobile/`), since model conversion is a project-level pipeline concern shared across all consumers (Streamlit, REST API, mobile).

---

## How It Works (Offline Pipeline)

```
Camera/Gallery → Resize to 224×224 → ImageNet Normalize → TFLite Model → Softmax → Result
                  (imageProcessor)    (classifier.ts)      (on-device     (top-5    + Disease
                                                           fast-tflite)   probs)     Info JSON
```

1. **Capture** — Camera captures a leaf photo or user picks from gallery
2. **Resize** — `imageProcessor.ts` resizes to 224x224 using platform-native APIs
3. **Pixel extract** — JPEG decoded to raw RGBA via `jpeg-js`
4. **Preprocess** — `classifier.ts` normalizes with ImageNet mean/std, layouts as NHWC tensor
5. **Inference** — TFLite model runs on-device (CoreML on iOS, GPU delegate on Android)
6. **Postprocess** — Apply softmax to raw logits, extract top-5 predictions
7. **Display** — Match top prediction to `disease_info.json` for symptoms, treatment, prevention
8. **Save** — Prediction saved to AsyncStorage for offline history

---

## Dependencies

### Runtime

| Package | Purpose |
|---------|---------|
| `react-native-fast-tflite` | On-device TFLite inference (CoreML on iOS, GPU delegate on Android) |
| `react-native-image-resizer` | Resize images to 224x224 for model input |
| `jpeg-js` | Pure-JS JPEG decoder for RGBA pixel extraction |
| `react-native-vision-camera` | Camera capture and permissions |
| `react-native-image-picker` | Gallery image selection |
| `react-native-fs` | Read resized images as base64 for decoding |
| `react-native-reanimated` | Smooth animations (confidence bars, expand/collapse) |
| `react-native-linear-gradient` | Gradient backgrounds (hero, buttons) |
| `react-native-vector-icons` | Ionicons throughout the UI |
| `@react-navigation/*` | Bottom tabs + stack navigation |
| `@react-native-async-storage` | Local prediction history |
| `react-native-safe-area-context` | Safe area handling |
| `react-native-screens` | Native screen containers |

### Dev

| Package | Purpose |
|---------|---------|
| `typescript` | Type safety (strict mode) |
| `@react-native/babel-preset` | Babel transforms |
| `@react-native/metro-config` | Metro bundler config |
| `@react-native/eslint-config` | Linting rules |
| `jest` | Testing |

---

## Scripts

| Command | Description |
|---------|-------------|
| `npm start` | Start Metro bundler (required for the app to load JS) |
| `npm run ios` | Build and run on iOS (tries to launch Metro in a new Terminal) |
| `npm run ios:no-packager` | Run on iOS without starting Metro (use when Metro is already running) |
| `npm run android` | Build and run on Android emulator |
| `npm run lint` | Run ESLint on TypeScript files |
| `npm run type-check` | Run TypeScript compiler check |
| `npm test` | Run Jest tests |

## End-to-End Testing (Maestro)

UI flows are in `.maestro/flows/`. Run them after building the app and exporting the TFLite model:

```bash
# Install Maestro: https://maestro.mobile.dev/getting-started/installation
# From mobile/
maestro test .maestro/flows/
```

For iOS, use: `maestro test -e appId=org.reactjs.native.example.CropDiseaseApp .maestro/flows/`

---

## Troubleshooting

### Model file not found

```
Error: Cannot find module or path for crop_disease_classifier.tflite
```

Run the export script first:
```bash
python scripts/export_model.py
```

### No script URL provided / packager not running

If the simulator shows a red error: *"No script URL provided. Make sure the packager is running..."*:

1. In a terminal, from the `mobile/` folder, run: **`npm start`** and leave it running.
2. In the simulator, press **⌘R** to reload the app, or run **`npm run ios:no-packager`** in a second terminal to rebuild and launch again.

### Camera permission denied (iOS)

Add to `ios/CropDiseaseApp/Info.plist`:
```xml
<key>NSCameraUsageDescription</key>
<string>We need camera access to scan leaf images for disease detection.</string>
<key>NSPhotoLibraryUsageDescription</key>
<string>We need photo library access to select leaf images for disease detection.</string>
```

### Camera permission denied (Android)

Add to `android/app/src/main/AndroidManifest.xml`:
```xml
<uses-permission android:name="android.permission.CAMERA" />
<uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE" />
```

### Pod install fails (iOS)

```bash
cd ios
pod deintegrate
pod install --repo-update
cd ..
```

### Metro bundler cache issues

```bash
npx react-native start --reset-cache
```
